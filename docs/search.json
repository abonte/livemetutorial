[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "SHB - data engineering module tutorial",
    "section": "",
    "text": "Follow these steps to set up the environment where to execute the data preparation code on your data.\n\nThe code is run inside a Docker container. A container includes all the dependencies needed to run the code (see what is a container). To get started, install Docker on you machine by downloading Docker Desktop.\nDownload the code following the instruction provided via email by the instructor.\nDownload the sensor folders inside &lt;PATH-TO-YOUR-FOLDER-CODE&gt;/experiments/shb/dump. The expected folder structure should be as follow:\n/\n├── src/                         # Contains the source code\n├── experiments/                 # Contains experiment data and configurations\n│   └── shb/                     # Experiment name e.g., shb\n│       ├── dump/\n|           ├── activities/\n|           ├── batterylevel/\n|           .\n|           .\n|           .\nstart the container. If you are using Windows, follow Data science with JupyterLab. Here are reported the main steps for Mac/Linux (the linked guide provides instructions for Windows) using the command line (the same steps can be performed from the Docker Desktop interface):\n\nopen a terminal and change the directory to where the code is (i.e., cd &lt;PATH-TO-YOUR-FOLDER-CODE&gt;)\nrun the following commnand\ndocker run  --rm -p 8889:8888 -v \"$(pwd):/src\" greatbee/shb2024\nopen the Jupyter Lab website in the browser at http://localhost:8889/lab?token=abcd\n\nopen the notebook named shb.ipynb in the project root\nFollow the steps inside the notebook to execute the data preparation pipeline. (introduction on Jupyter notebooks)\nTo stop the the container, ctrl+c in the terminal where the container is running\n\n\n\n\nTool to view parquet data"
  },
  {
    "objectID": "index.html#data-preparation",
    "href": "index.html#data-preparation",
    "title": "SHB - data engineering module tutorial",
    "section": "",
    "text": "Follow these steps to set up the environment where to execute the data preparation code on your data.\n\nThe code is run inside a Docker container. A container includes all the dependencies needed to run the code (see what is a container). To get started, install Docker on you machine by downloading Docker Desktop.\nDownload the code following the instruction provided via email by the instructor.\nDownload the sensor folders inside &lt;PATH-TO-YOUR-FOLDER-CODE&gt;/experiments/shb/dump. The expected folder structure should be as follow:\n/\n├── src/                         # Contains the source code\n├── experiments/                 # Contains experiment data and configurations\n│   └── shb/                     # Experiment name e.g., shb\n│       ├── dump/\n|           ├── activities/\n|           ├── batterylevel/\n|           .\n|           .\n|           .\nstart the container. If you are using Windows, follow Data science with JupyterLab. Here are reported the main steps for Mac/Linux (the linked guide provides instructions for Windows) using the command line (the same steps can be performed from the Docker Desktop interface):\n\nopen a terminal and change the directory to where the code is (i.e., cd &lt;PATH-TO-YOUR-FOLDER-CODE&gt;)\nrun the following commnand\ndocker run  --rm -p 8889:8888 -v \"$(pwd):/src\" greatbee/shb2024\nopen the Jupyter Lab website in the browser at http://localhost:8889/lab?token=abcd\n\nopen the notebook named shb.ipynb in the project root\nFollow the steps inside the notebook to execute the data preparation pipeline. (introduction on Jupyter notebooks)\nTo stop the the container, ctrl+c in the terminal where the container is running\n\n\n\n\nTool to view parquet data"
  },
  {
    "objectID": "index.html#liveme",
    "href": "index.html#liveme",
    "title": "SHB - data engineering module tutorial",
    "section": "2 LiveMe",
    "text": "2 LiveMe\nThis tutorial will guide you through the deployment of the LiveMe catalog and the upload of the metadata of the datasets generated during the course. The steps are run through the Github website, but if you know git commands, you can perform them through the command line. Alternatively to Github pages, you can use other software repositories like Codeberg and Gitlab. In that case, you can follow the same steps. See a demo of the catalog.\n\n2.1 Introduction to LiveMe\nThe LiveMe data catalog is a lightweight static website based on jkan.io. The website runs on GitHub Pages. JKAN is a tool for making open data websites. In this couse, only the metadata will be uploaded. The actual data is kept on the student’s device. JKAN is backend-free and the business logic, maintained in the reference Github repository, is developed in node js and is executed directly from the repository as Github pages. Once the reference Github repository is set up, the catalog can go online immediately. It is accessible through the link provided by its github webpage. The development and maintenance of the catalog can be done entirely on the repository, all the modifications performed there will be directly available online on the webpage. Being based on Github, the JKAN catalog can be updated only by users who have access to the repository.\n\n\n2.2 Getting started\nPrerequisites:\n\nCreate a new LiveMe catalog from the catalog template.\nProvide a Repository Name (in the rest of this tutorial, we assume the name is liveme), and then Create Repository.\n\nOnce your repository is created, update the website configuration file with your information.\n\nGo on your repository https://github.com/&lt;GITHUB_USERNAME&gt;/liveme\nModify the _config.yml file by clicking on it and on Edit this file button\n\n\n\nChange the value of the following properties like in the example below:\n\ntitle: LiveMe\ngreeting: LiveMe Catalog of &lt;YOUR_NAME&gt; \ndescription: Personal data catalog of &lt;YOUR_NAME&gt;.\nbaseurl: /liveme\n\nClick the Commit changes button to save the configuration (it might take few seconds before the changes are published on the website).\n\nOnce the configuration is updated, you can look how the website looks like at the following URL https://&lt;GITHUB_USERNAME&gt;.github.io/&lt;REPOSITORY_NAME&gt;/, where &lt;GITHUB_USERNAME&gt;is replaced with your Github username and &lt;REPOSITORY_NAME&gt;is the name of the repository you defined in the previous step (e.g., https://abonte.github.io/liveme/).\n\n\n\n\n\n\n\nNote\n\n\n\nBy default, the repository and the website are visible to the public. Github and the other source repositories allow to restric the access by publishing them privately. If the visualization is set to private, remember to give permission to the professor to access the webpage and the repository.\n\n\n\n\n2.3 Repository structure\nIn this section, we describe the structure of the JKAN template repository that Datascientia provides to set up a new catalog. Below, we describe the most important elements for this course.\n\n_data : this directory contains the yml configuration files used to define the metadata of the resources handled by the catalog (within the “schemas” directory), as well as the categories that can be used to categorize the resources in the catalogs, and the customs services which can accessed to the catalog.\n_datasets : this directory stores the markdown file describing (following a precise metadata schema) each dataset uploaded in the catalog.\n_organizations : similar to the _datasets directory, this one contains the markdown files defining the organization that have uploaded (the owner usually) datasets in the catalog.\n_config.yml : this is the main config file of the JAKN catalog.\ndatasets.json : this file defines the structure of each dataset that can be searched within the catalog. This file is used for the search functionality mostly, this means that, in order to be searchable, the datasets in the catalog need to respect the structure in this file, which can be updated in order to add new search criteria.\n\nOther folders in the repository:\n\n_includes : this directory contains the website pages (html files) that are shown in the catalog web page.\ncss : it contains the catalog main.css style file.\nimg : it contains the images used in the catalog website.\nscripts : this directory contains the business logic of the JKAN catalog. More in detail, in the “src” subdirectory we can find the javascript code divided in the different files, containing different specific functions. While in the “dist” subdirectory we can find the bundle.js file that is the file created after building the code in the src subdirectory. The bundle.js file is the only file that is actually executed in order to apply the JKAN business logic to the catalog. This means that all the modification performed in the source code (src subdirectory) needs to be reported in the bundle.js file too, this happens automatically running the build process (see the next section for the instruction about how to make a new build locally).\nIndex.html : this is the main html file of the catalog webpage. The visualization of the catalog website, as well as its navigation, starts from this file.\n\n\n\n2.4 Add a new organization (you)\nThe organization is the individual or the entity (the owner usually) that has uploaded datasets in the catalog. In LiveMe, the organization uploading the data is the owner of the personal catalog.\nTo add yourself as an organization to the catalog follow these steps.\n\nCreate a new file named &lt;YOUR_NAME&gt;.md inside the _organization folder in the repository.\n\nPaste the following text and change it with your information.\n---\nschema: default\n1title: &lt;YOUR_NAME&gt;\ndescription: &lt;YOUR_NAME&gt; is a student of the Studies on Human Behavior course of the University of Trento.\n---\n\n1\n\nMake sure that the value matches the filename.\n\n\nAfter a few seconds, the created organization is visible on the website. All dataset metadata that you upload will belog to this organization.\n\n\n\n2.5 Add manually a new dataset metadata\n\n\n\n\n\n\nImportant\n\n\n\nDo not upload the actual data (sensor data or answer to the questions) in the catalog repository. This data must be kept on your device and the storage provided.\n\n\nTo a new dataset, you need to create a new markdown file containing the metadata that describe the dataset. The metadata follows a defined schema (see _data/schemas/default.yml).\n\nCreate a new file named &lt;DATASET_NAME&gt;.md inside the _datasets folder in the repository (similarly to Section 2.4).\nPaste the following text and change with your information.\n---\nschema: default\ntitle: First dataset\n1organization: &lt;YOUR_NAME&gt;\nnotes: This is my first dataset on my new JKAN catalog\nresources:\n    - name: Air Monitoring Stations CSV\n        url: &gt;-\n            http://data.phl.opendata.arcgis.com/datasets/1839b35258604422b0b520cbb668df0d_0.csv\n        format: csv\nlicense: 'https://www.nationalarchives.gov.uk/doc/open-government-licence/version/3/'\ncategory:\n    - Personal data\ntype:\n    - Documentation\nmaintainer: Tim Wisniewski\nmaintainer_email: tim@timwis.com\ntags: parquet\n---\n\n1\n\nMake sure that the organization name matches the name you defined in Section 2.4.\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nIndentation matter; be sure to respect the structure!\n\n\n\nAfter a few seconds, the dataset is visible on the website.\n\n\n\n2.6 Add new datasets metadata and codebooks a the end of the data preparation pipeline\nThe data processing pipeline on your personal data automatically generates the markdown files and codebooks for each sensor collected.\n\nThe markdown files are gerated in experiments/shb/docs/markdowns. You just need to upload all the files inside the _datasets folder in the repository. To perform a bulk upload, navigate to the _datasets folder in you repository https://github.com/&lt;GITHUB_USERNAME&gt;/liveme and select Upload files inside. Then, follow the instructions.\n\n\n\nThe codebooks are stored inside experiments/shb/docs/codebooks. Upload all the files in the documentation/codebooks folder inside the repository as described in the previous point.\nAfter a few seconds, the changes are visible on the website. I the following icon is visible in the repository, the website is not yet ready.\n\n\n\n\n2.7 References\n\nDS Catalog: Development and Maintenance\nPersonal Datascientia Public Portfolio\nDelete your Datascientia account"
  }
]